{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<h1><b>Acquisition automatique de Donn√©es : Brevet"],"metadata":{"id":"JJBar6eBTfML"}},{"cell_type":"markdown","source":["L'objectif principal de ce projet est d'automatiser la collecte et l'analyse de brevets concernant la 6G et la s√©curit√© dans un fichier .csv, en se focalisant sur des brevets qu‚Äôon a retrouv√© sur Google Patents, ensuite de cr√©er une application qui permet la visualisation des donn√©es extraites dans le brevets."],"metadata":{"id":"8OPX2_ZdUXLp"}},{"cell_type":"markdown","source":["\n","\n","*   <h2>Receuils des brevets\n","\n"],"metadata":{"id":"sv7iANjtWMY6"}},{"cell_type":"code","source":["!pip install aiohttp aiofiles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"1G2K2r4tJjJx","executionInfo":{"status":"ok","timestamp":1746874200479,"user_tz":-120,"elapsed":10217,"user":{"displayName":"Emmanuel Danton","userId":"16748182698026473705"}},"outputId":"a71f2717-38ef-4d4a-cd5b-63645b89eef9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (3.11.15)\n","Collecting aiofiles\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.20.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp) (3.10)\n","Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Installing collected packages: aiofiles\n","Successfully installed aiofiles-24.1.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Monter Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7FhVZk_nJvBC","executionInfo":{"status":"ok","timestamp":1746874227021,"user_tz":-120,"elapsed":19585,"user":{"displayName":"Emmanuel Danton","userId":"16748182698026473705"}},"outputId":"1ba57330-25ab-414b-dc01-0ee1c891c6d0","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import aiohttp\n","import asyncio\n","from aiofiles import open as aio_open\n","import time\n","\n","\n","# --- CONSTANTES ---\n","URL_BASE = \"https://patents.google.com/patent/US{}\"\n","\n","# Chemins des fichiers pour la gestion des brevets\n","fichier_brevets = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_urls.txt\"\n","fichier_csv = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_6G.csv\"\n","fichier_brevets_traite = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_traite.txt\"\n","fichier_dernier_brevet = \"/content/drive/MyDrive/acquisitionbrevet/brevets/dernier_brevet.txt\"\n","\n","# --- Mots-cl√©s li√©s √† la 6G ---\n","MOTS_CLES_6G = [\n","    \"terahertz communication\",\n","    \"THz\",\n","    \"massive MIMO\",\n","    \"ultra-massive MIMO\",\n","    \"reconfigurable intelligent surfaces\",\n","    \"RIS\",\n","    \"artificial intelligence\",\n","    \"AI\",\n","    \"machine learning\",\n","    \"blockchain\",\n","    \"distributed ledger technology\",\n","    \"DLT\",\n","    \"energy harvesting\",\n","    \"quantum communication\",\n","    \"non-terrestrial networks\",\n","    \"NTN\",\n","    \"visible light communication\",\n","    \"VLC\",\n","    \"orbital angular momentum\",\n","    \"OAM\",\n","    \"6G frequency bands\",\n","    \"digital twins\",\n","    \"photonic communication\",\n","    \"holographic communication\",\n","    \"self-sustaining networks\",\n","    \"enhanced security and privacy\",\n","    \"ultra-low latency\",\n","    \"ultra-high speed\",\n","    \"terabit-per-second\",\n","    \"advanced beamforming\",\n","    \"RIS channel modeling\",\n","    \"RIS-network integration\",\n","    \"Privacy\",\n","    \"Data\",\n","    \"Security\",\n","    \"Privacy Policies\",\n","    \"Device Sensors\",\n","    \"Network Slicing\",\n","    \"Edge Computing\",\n","    \"Ultra-dense networks\",\n","    \"Zero-touch networks\",\n","    \"Massive IoT\",\n","    \"Autonomous Vehicles\",\n","    \"Smart Cities\",\n","    \"Artificial General Intelligence\",\n","    \"Self-Organizing Networks\",\n","    \"Blockchain for Network Management\",\n","    \"Direct Device-to-Device Communication\",\n","    \"Cognitive Radio\",\n","    \"Massive Cloud-RAN\",\n","    \"Ambient Intelligence\",\n","    \"Heterogeneous Networks\",\n","    \"Molecular Communication\"\n","]\n","\n","\n","# --- FONCTION DE VALIDATION (ASYNCHRONE) ---\n","async def est_brevet_valide(session, numero_brevet):\n","    url = URL_BASE.format(numero_brevet)\n","    try:\n","        async with session.get(url, timeout=10) as reponse:\n","            if reponse.status == 200:\n","                contenu = await reponse.text()\n","                if any(mot_cle in contenu.lower() for mot_cle in MOTS_CLES_6G):\n","                    return url\n","    except Exception as e:\n","        print(f\"Erreur lors de la v√©rification du brevet {numero_brevet}: {e}\")\n","    return None\n","\n","# --- CHARGEMENT DES URLS D√âJ√Ä ENREGISTR√âES ---\n","async def charger_urls_existantes():\n","    try:\n","        async with aio_open(fichier_brevets_traite, \"r\") as f:\n","            return {ligne.strip() for ligne in await f.readlines()}\n","    except FileNotFoundError:\n","        return set()\n","\n","# --- D√âTERMINER LE DERNIER NUM√âRO PARCOURU ---\n","async def obtenir_dernier_brevet():\n","    try:\n","        async with aio_open(fichier_dernier_brevet, \"r\") as f:\n","            dernier_numero = await f.read()\n","            return int(dernier_numero.strip()) if dernier_numero.strip().isdigit() else 10318759\n","    except Exception:\n","        return 10318759\n","\n","# --- MISE √Ä JOUR DES FICHIERS ---\n","async def mettre_a_jour_fichiers(nouveaux_brevets, dernier_numero):\n","    async with aio_open(fichier_brevets, \"a\") as f:\n","        await f.writelines(f\"{url}\\n\" for url in nouveaux_brevets)\n","\n","    async with aio_open(fichier_brevets_traite, \"a\") as f:\n","        await f.writelines(f\"{url}\\n\" for url in nouveaux_brevets)\n","\n","    async with aio_open(fichier_dernier_brevet, \"w\") as f:\n","        await f.write(str(dernier_numero))\n","\n","# --- ACQUISITION ASYNCHRONE DES BREVETS ---\n","async def acquisition_brevets(nombre_a_verifier):\n","    debut_temps = time.time()\n","\n","    urls_traitees = await charger_urls_existantes()\n","    dernier_brevet = await obtenir_dernier_brevet()\n","\n","    print(f\"D√©marrage de la recherche √† partir du num√©ro : {dernier_brevet}\")\n","    nouveaux_brevets = []\n","\n","    async with aiohttp.ClientSession() as session:\n","        taches = []\n","        for i in range(nombre_a_verifier):\n","            numero_courant = dernier_brevet + i\n","            numero_brevet = f\"{numero_courant}B2\"\n","\n","            if any(numero_brevet in url for url in urls_traitees):\n","                print(f\"üîÅ D√©j√† trait√© pour US{numero_brevet}\")\n","                continue\n","\n","            taches.append(est_brevet_valide(session, numero_brevet))\n","\n","        resultats = await asyncio.gather(*taches)\n","\n","        for url in resultats:\n","            if url:\n","                nouveaux_brevets.append(url)\n","                print(f\"‚úÖ Nouveau brevet trouv√© : {url}\")\n","\n","    # Mise √† jour des fichiers\n","    await mettre_a_jour_fichiers(nouveaux_brevets, dernier_brevet + nombre_a_verifier)\n","\n","    # R√©sum√© de l'ex√©cution\n","    fin_temps = time.time()\n","    print(f\"üîç Nombre total de brevets trouv√©s : {len(nouveaux_brevets)}\")\n","    print(f\"‚è±Ô∏è Temps total d'ex√©cution : {fin_temps - debut_temps:.2f} secondes\")\n","    print(\"üöÄ R√©cup√©ration des brevets termin√©e. Fichiers mis √† jour.\")\n","\n","# --- EX√âCUTION DU SCRIPT ---\n","await acquisition_brevets(nombre_a_verifier=100)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"HPGcVlRcJ0B9","outputId":"c500f36d-1d02-4817-e8f9-c9928b73ccd2","executionInfo":{"status":"ok","timestamp":1746874251263,"user_tz":-120,"elapsed":19469,"user":{"displayName":"Emmanuel Danton","userId":"16748182698026473705"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["D√©marrage de la recherche √† partir du num√©ro : 10319359\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319363B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319364B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319366B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319367B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319368B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319369B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319370B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319372B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319373B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319374B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319375B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319376B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319378B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319379B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319381B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319390B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319391B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319395B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319407B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319412B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319428B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319441B2\n","‚úÖ Nouveau brevet trouv√© : https://patents.google.com/patent/US10319444B2\n","üîç Nombre total de brevets trouv√©s : 23\n","‚è±Ô∏è Temps total d'ex√©cution : 19.18 secondes\n","üöÄ R√©cup√©ration des brevets termin√©e. Fichiers mis √† jour.\n"]}]},{"cell_type":"markdown","source":["\n","\n","\n","\n","\n","*    <h2> Extraction de donn√©es des brevets"],"metadata":{"id":"bfGRyQS2L_He"}},{"cell_type":"code","source":["import aiofiles\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","\n","\n","# --- CONSTANTES ---\n","BASE_URL = \"https://patents.google.com\"\n","fichier_brevets = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_urls.txt\"\n","fichier_csv = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_6G.csv\"\n","\n","# --- COLONNES DANS L'ORDRE DEMAND√â ---\n","COLUMNS = [\n","    \"Lien\", \"Num√©ro Brevet\", \"Titre\", \"Date de publication\", \"Mots-cl√©s\",\n","    \"Description\", \"Domaine Technologique\", \"Inventeurs\", \"Titulaire du brevet\",\n","    \"Statut du brevet\"\n","]\n","\n","# --- Liste des stopwords √† supprimer ---\n","STOPWORDS = {\"a\", \"and\", \"that\", \"to\", \"be\", \"in\", \"the\", \"of\",\"an\",\"one\",\"present\",\"some\",\"for\",\"are\",\"is\",\"with\",\"this\",\"provided\",\"herein\",\"or\",\"more\",\"each\",\"includes\",\"include\"}\n","\n","# --- Charger les brevets d√©j√† trait√©s ---\n","def load_processed_patents():\n","    try:\n","        df = pd.read_csv(fichier_csv)\n","        return set(df[\"Num√©ro Brevet\"].dropna().unique())\n","    except FileNotFoundError:\n","        return set()\n","\n","\n","# --- D√©tection du domaine technologique ---\n","def detect_technology_field(title, abstract):\n","    \"\"\" Cat√©gorisation automatique des brevets selon leur domaine technologique. \"\"\"\n","    keywords = {\n","    \"T√©l√©communications\": [\n","        \"5G\", \"6G\", \"network\", \"antenna\", \"MIMO\", \"massive MIMO\", \"ultra-massive MIMO\",\n","        \"signal\", \"terahertz communication\", \"THz\", \"6G frequency bands\", \"advanced beamforming\",\n","        \"RIS\", \"RIS channel modeling\", \"RIS-network integration\", \"non-terrestrial networks\", \"NTN\",\n","        \"visible light communication\", \"VLC\", \"orbital angular momentum\", \"OAM\", \"ultra-high speed\",\n","        \"terabit-per-second\", \"network slicing\", \"ultra-dense networks\", \"direct device-to-device communication\",\n","        \"heterogeneous networks\", \"massive Cloud-RAN\"\n","        ],\n","    \"Intelligence Artificielle\": [\n","        \"artificial intelligence\", \"AI\", \"machine learning\", \"deep learning\", \"neural network\",\n","        \"artificial general intelligence\", \"ambient intelligence\", \"cognitive radio\", \"self-organizing networks\",\n","        \"zero-touch networks\"\n","        ],\n","    \"S√©curit√©\": [\n","        \"cryptography\", \"authentication\", \"security\", \"hacking\", \"protection\", \"enhanced security and privacy\",\n","        \"privacy\", \"privacy policies\", \"data\", \"blockchain\", \"distributed ledger technology\", \"DLT\",\n","        \"blockchain for network management\"\n","        ],\n","    \"√ânergie\": [\n","        \"battery\", \"energy\", \"recharge\", \"autonomy\", \"energy harvesting\", \"self-sustaining networks\"\n","        ],\n","    \"Quantique\": [\n","        \"quantum\", \"qubit\", \"quantum communication\", \"molecular communication\"\n","        ],\n","    \"IoT et R√©seaux\": [\n","        \"massive IoT\", \"device sensors\", \"smart cities\", \"autonomous vehicles\", \"edge computing\"\n","        ],\n","    \"Communication Avanc√©e\": [\n","        \"photonic communication\", \"holographic communication\", \"digital twins\"\n","        ]\n","}\n","\n","    for field, words in keywords.items():\n","        if any(word.lower() in (title + abstract).lower() for word in words):\n","            return field\n","    return \"Autre\"\n","\n","\n","# --- EXTRACTION ASYNCHRONE DES BREVETS ---\n","async def fetch_patent_details(session, url):\n","    \"\"\" R√©cup√®re et extrait les informations principales d'un brevet. \"\"\"\n","    try:\n","        async with session.get(url, timeout=10) as response:\n","            if response.status == 200:\n","                content = await response.text()\n","                soup = BeautifulSoup(content, \"html.parser\")\n","\n","                # üìå Extraction du Titre via <meta name=\"DC.title\">\n","                title_tag = soup.find(\"meta\", {\"name\": \"DC.title\"})\n","                title = title_tag[\"content\"].strip() if title_tag else \"Non trouv√©\"\n","                patent_number = url.split(\"/\")[-1]\n","                # üìå Extraction de la Date de publication\n","                pub_date = soup.find(\"meta\", {\"name\": \"DC.date\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"DC.date\"}) else \"Non trouv√©\"\n","\n","                # üìå R√©cup√©ration des inventeurs\n","                inventors = \", \".join([tag.text.strip() for tag in soup.find_all(itemprop=\"inventor\")]) or \"Non trouv√©\"\n","\n","                # üìå R√©cup√©ration du titulaire du brevet (anciennement \"Assignee\")\n","                assignees = \", \".join([tag.text.strip() for tag in soup.find_all(itemprop=\"assigneeCurrent\")]) or \"Non trouv√©\"\n","\n","                # üìå R√©cup√©ration du r√©sum√© (description)\n","                abstract = soup.find(\"meta\", {\"name\": \"DC.description\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"DC.description\"}) else \"Non trouv√©\"\n","\n","                # üìå D√©tection du domaine technologique\n","                domain = detect_technology_field(title, abstract)\n","\n","                # üìå Extraction du statut via itemprop \"legalStatusIfi\"\n","                status_tag = soup.find(itemprop=\"legalStatusIfi\")\n","                status = status_tag.text.strip() if status_tag else \"Inconnu\"\n","\n","                # üìå G√©n√©ration des mots-cl√©s (filtr√©s)\n","                words = [word for word in abstract.split()[:10] if word.lower() not in STOPWORDS]\n","                keywords = \", \".join(words)\n","\n","\n","\n","                return {\n","                    \"Lien\": url,\n","                    \"Num√©ro Brevet\": patent_number,\n","                    \"Titre\": title,\n","                    \"Date de publication\": pub_date,\n","                    \"Mots-cl√©s\": keywords,\n","                    \"Description\": abstract,\n","                    \"Domaine Technologique\": domain,\n","                    \"Inventeurs\": inventors,\n","                    \"Titulaire du brevet\": assignees,\n","                    \"Statut du brevet\": status\n","                }\n","    except Exception as e:\n","        print(f\"‚ùå Erreur lors de l'extraction de {url} : {e}\")\n","    return None\n","\n","# --- CHARGER LES BREVETS TROUV√âS ---\n","async def load_patent_urls():\n","    try:\n","        async with aiofiles.open(fichier_brevets, \"r\") as f:\n","            urls = [line.strip() for line in await f.readlines() if line.strip()]\n","            return urls\n","    except FileNotFoundError:\n","        print(\"üìÅ Fichier patent_urls.txt introuvable. V√©rifie le chemin.\")\n","        return []\n","\n","# --- SAUVEGARDE EN CSV ---\n","async def save_to_csv(data):\n","    df = pd.DataFrame(data, columns=COLUMNS)\n","    try:\n","        existing_df = pd.read_csv(fichier_csv)\n","        df = pd.concat([existing_df, df], ignore_index=True)\n","    except FileNotFoundError:\n","        pass\n","    df.to_csv(fichier_csv, index=False)\n","    print(f\"‚úÖ {len(data)} brevets ajout√©s √† {fichier_csv}\")\n","\n","# --- LANCEMENT DE L'EXTRACTION ---\n","async def extract_patents_data():\n","    urls = await load_patent_urls()\n","    if not urls:\n","        print(\"‚ö†Ô∏è Aucun brevet √† extraire.\")\n","        return\n","\n","    processed_patents = load_processed_patents()\n","    urls_to_process = [url for url in urls if url.split(\"/\")[-1] not in processed_patents]\n","\n","    if not urls_to_process:\n","        print(\"‚úÖ Tous les brevets sont d√©j√† trait√©s.\")\n","        return\n","\n","    print(f\"üîç Extraction des donn√©es pour {len(urls_to_process)} brevets...\")\n","\n","    async with aiohttp.ClientSession() as session:\n","        tasks = [fetch_patent_details(session, url) for url in urls_to_process]\n","        results = await asyncio.gather(*tasks)\n","\n","    valid_results = [res for res in results if res is not None]\n","    if valid_results:\n","        await save_to_csv(valid_results)\n","    else:\n","        print(\"‚ö†Ô∏è Aucune donn√©e valide extraite.\")\n","\n","# --- EX√âCUTION DU SCRIPT ---\n","await extract_patents_data()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"SOfWNUtGWrGW","executionInfo":{"status":"ok","timestamp":1746874436548,"user_tz":-120,"elapsed":13061,"user":{"displayName":"Emmanuel Danton","userId":"16748182698026473705"}},"outputId":"01044362-54a7-4eb4-93a0-82931519c607"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Extraction des donn√©es pour 25 brevets...\n","‚úÖ 25 brevets ajout√©s √† /content/drive/MyDrive/acquisitionbrevet/brevets/brevets_6G.csv\n"]}]},{"cell_type":"code","source":["# --- CONFIGURATION ---\n","from google.colab import userdata\n","userdata.get('secretName')\n","CSV_FILE = \"/content/drive/MyDrive/acquisitionbrevet/brevets/brevets_6G.csv\"\n","BATCH_SIZE = 10  # Nombre de brevets √† traiter par ex√©cution"],"metadata":{"id":"JPD7w34P4vQa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*    <h2> Ajouts des colonnes de R√©sum√©, Probl√®me et Solution aux donn√©es extraites"],"metadata":{"id":"9rOYftbLMtte"}},{"cell_type":"code","source":["import os\n","import time\n","import pandas as pd\n","import asyncio\n","import json\n","import aiohttp\n","import nest_asyncio\n","\n","nest_asyncio.apply()\n","\n","\n","PROMPT_TEMPLATE = \"\"\"\n","Analyze the following patent description and extract:\n","- Summary of the patent in 2 to 3 sentences.\n","- Problem addressed\n","- Solution provided\n","\n","Description:\n","{content}\n","\n","Return the response in JSON format:\n","{{\n","  \"summary\": \"...\",\n","  \"problem\": \"...\",\n","  \"solution\": \"...\"\n","}}\n","\"\"\"\n","\n","# --- FONCTION D'ANALYSE ---\n","async def analyze_patent(content):\n","    \"\"\" Analyse un brevet et extrait R√©sum√©, Probl√®me et Solution via OpenRouter \"\"\"\n","    if not content or pd.isna(content) or content.strip() == \"\":\n","        return \"\", \"\", \"\"\n","\n","    prompt = PROMPT_TEMPLATE.format(content=content)\n","\n","    headers = {\n","        \"Authorization\": f\"Bearer {API_KEY}\",\n","        \"Content-Type\": \"application/json\"\n","    }\n","\n","    payload = {\n","        \"model\": MODEL_ID,\n","        \"messages\": [\n","            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","            {\"role\": \"user\", \"content\": prompt}\n","        ],\n","        \"max_tokens\": 500\n","    }\n","\n","    try:\n","        async with aiohttp.ClientSession() as session:\n","            async with session.post(\"https://openrouter.ai/api/v1/chat/completions\", json=payload, headers=headers) as response:\n","                response_json = await response.json()\n","\n","                if \"choices\" not in response_json:\n","                    print(f\"‚ö†Ô∏è R√©ponse API invalide: {response_json}\")\n","                    return \"\", \"\", \"\"\n","\n","                result = response_json[\"choices\"][0][\"message\"][\"content\"]\n","\n","                # V√©rifie si la r√©ponse est bien un JSON\n","                try:\n","                    data = json.loads(result)\n","                except json.JSONDecodeError:\n","                    print(f\"‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\\n{result}\")\n","                    return \"\", \"\", \"\"\n","\n","                return data.get(\"summary\", \"\"), data.get(\"problem\", \"\"), data.get(\"solution\", \"\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå Erreur API: {e}\")\n","        return \"\", \"\", \"\"\n","\n","# --- TRAITEMENT CSV ---\n","async def process_csv():\n","    \"\"\" Charge le fichier CSV, analyse les brevets manquants et met √† jour les r√©sultats. \"\"\"\n","    try:\n","        df = pd.read_csv(CSV_FILE, dtype=str).fillna(\"\")\n","    except FileNotFoundError:\n","        print(f\"‚ùå Erreur: Fichier {CSV_FILE} introuvable.\")\n","        return\n","\n","    # Ajouter les colonnes si elles n'existent pas\n","    for col in [\"R√©sum√©\", \"Probl√®me\", \"Solution\"]:\n","        if col not in df.columns:\n","            df[col] = \"\"\n","\n","    # S√©lection des brevets ayant au moins une colonne vide, et qui ne sont pas d√©j√† compl√©t√©s\n","    to_analyze = df[(df[[\"R√©sum√©\", \"Probl√®me\", \"Solution\"]] == \"\").any(axis=1) & (df[\"Description\"].str.strip() != \"\")].head(BATCH_SIZE)\n","\n","    if to_analyze.empty:\n","        print(\"‚úÖ Tous les brevets ont d√©j√† √©t√© analys√©s !\")\n","        return\n","\n","    print(f\"üîç Nombre de brevets √† analyser: {len(to_analyze)}\")\n","\n","    tasks = []\n","    indices = []\n","\n","    for idx, row in to_analyze.iterrows():\n","        description = row[\"Description\"]\n","        if description.strip():  # V√©rifier que la description n'est pas vide\n","            tasks.append(analyze_patent(description))\n","            indices.append(idx)\n","        else:\n","            print(f\"‚ö†Ô∏è Brevet {idx} ignor√© car sans description.\")\n","\n","    # Ex√©cuter les requ√™tes en parall√®le\n","    results = await asyncio.gather(*tasks)\n","\n","    # Mise √† jour du DataFrame avec les r√©sultats uniquement si la colonne est vide\n","    for idx, (summary, problem, solution) in zip(indices, results):\n","        if df.at[idx, \"R√©sum√©\"] == \"\":\n","            df.at[idx, \"R√©sum√©\"] = summary\n","        if df.at[idx, \"Probl√®me\"] == \"\":\n","            df.at[idx, \"Probl√®me\"] = problem\n","        if df.at[idx, \"Solution\"] == \"\":\n","            df.at[idx, \"Solution\"] = solution\n","\n","    # Sauvegarde propre du fichier sans √©craser les donn√©es existantes\n","    try:\n","        df.to_csv(CSV_FILE, index=False, encoding='utf-8')\n","        print(f\"‚úÖ Mise √† jour termin√©e ! {len(indices)} brevets analys√©s.\")\n","    except Exception as e:\n","        print(f\"‚ùå Erreur d'√©criture du fichier CSV: {e}\")\n","\n","# --- EXECUTION ---\n","await process_csv()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ah6eVNcTzzk6","executionInfo":{"status":"ok","timestamp":1746876170631,"user_tz":-120,"elapsed":10902,"user":{"displayName":"Emmanuel Danton","userId":"16748182698026473705"}},"outputId":"304c1f71-69d3-4171-e859-bda582323e75","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nombre de brevets √† analyser: 10\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","```json\n","{\n","  \"summary\": \"This patent describes a system for validating the authenticity of tags along a supply chain. It involves detecting a tag at a waypoint, obtaining values from it, using cryptographic methods to transform and store these values, and then validating the tag's authenticity at a later waypoint using stored records.\",\n","  \"problem\": \"The problem addressed is the need to ensure the authenticity and integrity of tags in a supply chain, likely to prevent counterfeiting or tampering.\",\n","  \"solution\": \"The solution provides a method that uses cryptographic techniques, including public/private key pairs and hashing, to create transaction records of tag data. These records and the transformed data are used to validate the authenticity of the tag at subsequent waypoints along the supply chain.\"\n","}\n","```\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","{\n","  \"summary\": \"A method and device detect non-visible content in an object via a light source emitting light over time, an optical sensor recording light patterns, and a processing component analyzing temporal changes in patterns to identify motion, which indicates non-visible content like vibrations or frequency changes.\",\n","  \"problem\": \"To detect subtle non-visible characteristics (e.g., vibrations, internal motion) of an object without physical contact, enabling real-time monitoring of hidden content.\",\n","  \"solution\": \"A non-contact device using structured light emission, optical sensing, and temporal\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","```json\n","{\n","  \"summary\": \"The patent describes a two-dimensional barcode combining preprinted information with coded sensor data that records environmental, physical, or biological changes. Sensor modules embedded in the barcode use dye chemistry to encode digital information via color changes when specific conditions are met. The error-correction feature ensures accurate recovery of sensor data during barcode reading.\",\n","  \"problem\": \"Reliably combining static preprinted data with dynamic sensor information in a barcode while ensuring accurate retrieval\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","```json\n","{\n","  \"summary\": \"The patent introduces a system for efficient real estate information retrieval using automated optical character recognition (OCR) on scanned documents, extracting and contextualizing data to provide search results with minimal human intervention.\",\n","  \"problem\": \"Time-consuming and error-prone manual processing of real estate-related documents when searching for information.\",\n","  \"solution\": \"Implement an automated system that uses OCR on scanned documents, extracts textual data, contextualizes real estate-related information, and generates search results from the processed data.\"\n","}\n","```\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","```json\n","{\n","  \"summary\": \"A housing includes two vertical tubular portions with radial cavities connected by a light path, arranged along a central axis. The first cavity channels incoming light to the second cavity, which houses an optical component. Both portions form a single monolithic member, enabling efficient vertical light transmission through radial pathways.\",\n","  \"problem\": \"Existing optical housings may not effectively combine vertical alignment with radial light pathways, limiting efficient light transmission in multi-directional setups.\",\n","  \"solution\": \"The housing integrates vertical extension and radial cavities into a single monolithic structure,\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","```json\n","{\n","  \"summary\": \"A system for vector extraction uses a network-connected computing device to load raster images from a database, identify features, and compute vectors automatically, supported by methods for feature and vector extraction.\",\n","  \"problem\": \"Inefficient or manual vector extraction from raster images stored in databases.\",\n","  \"solution\": \"An automated vector extraction system that processes raster images using a network-connected computing device, extracting features and generating vectors through engineered methods.\"\n","}\n","```\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","{\n","  \"summary\": \"The patent describes a system and method for image correlation and distribution that analyzes images containing people, along with metadata, contact data, facial recognition data, and location data. By combining facial recognition and location data, the method determines the identity of individuals in the image. This approach integrates multiple data types to improve accuracy and efficiency in identity verification.\",\n","  \"problem\": \"Accurate\n","‚ö†Ô∏è Erreur JSON: R√©ponse brute non valide\n","{\n","  \"summary\": \"A presentation scanner uses a partially reflecting surface and an aiming pattern to guide object placement within its field of view, enabling precise alignment via reflection of the object onto the target pattern. The system projects a target indicator onto the reflective surface, allowing operators to adjust the object until it overlaps with the pattern, ensuring accurate scanning. A camera captures the optical code once the object is correctly aligned.\",\n","  \"problem\": \"Difficulty in precisely positioning\n","‚úÖ Mise √† jour termin√©e ! 10 brevets analys√©s.\n"]}]},{"cell_type":"markdown","source":["*    <h2> Ajout du fichier sur un d√©p√¥t Github"],"metadata":{"id":"z0tRNgdF0Qwk"}},{"cell_type":"code","source":["!pip install PyGithub\n"],"metadata":{"id":"DSgERQSAxWex","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1746874578824,"user_tz":-120,"elapsed":4656,"user":{"displayName":"Emmanuel Danton","userId":"16748182698026473705"}},"outputId":"7a88a64c-e44d-4cd3-caf3-9d983604724e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyGithub\n","  Downloading PyGithub-2.6.1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting pynacl>=1.4.0 (from PyGithub)\n","  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n","Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (2.32.3)\n","Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (4.13.2)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (2.4.0)\n","Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from PyGithub) (1.2.18)\n","Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n","Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub) (1.17.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (2025.4.26)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->PyGithub) (1.17.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.22)\n","Downloading PyGithub-2.6.1-py3-none-any.whl (410 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pynacl, PyGithub\n","Successfully installed PyGithub-2.6.1 pynacl-1.5.0\n"]}]},{"cell_type":"code","source":["from github import Github\n","import os\n","\n","# --- CONFIGURATION GITHUB ---\n","REPO_NAME = \"emmanueldanton/acquisitionbrevets6G\"  # Format correct du d√©p√¥t\n","FILE_PATH = \"/content/drive/MyDrive/acquisitionbrevet/Acquisition_Automatique_De_Donnees_Brevet.ipynb\"\n","GITHUB_FILE_PATH = \"brevets_6G.csv\"  # Nom du fichier dans le repo\n","BRANCH = \"main\"  # Branche cible\n","\n","def upload_file_to_github():\n","    try:\n","        # Connexion √† GitHub\n","        g = Github(GITHUB_TOKEN)\n","        repo = g.get_repo(REPO_NAME)\n","\n","        # Lecture du fichier local\n","        with open(FILE_PATH, \"r\", encoding=\"utf-8\") as file:\n","            file_content = file.read()\n","\n","        # V√©rification si le fichier existe d√©j√† dans le repo\n","        try:\n","            existing_file = repo.get_contents(GITHUB_FILE_PATH, ref=BRANCH)\n","            sha = existing_file.sha  # R√©cup√©rer le SHA du fichier\n","            repo.update_file(\n","                GITHUB_FILE_PATH,\n","                \"Mise √† jour automatique du fichier brevets_6G.csv\",\n","                file_content,\n","                sha,  # SHA obligatoire pour update\n","                branch=BRANCH\n","            )\n","            print(\"‚úÖ Fichier mis √† jour avec succ√®s sur GitHub.\")\n","        except Exception:\n","            # Si le fichier n'existe pas, on le cr√©e\n","            repo.create_file(\n","                GITHUB_FILE_PATH,\n","                \"Ajout automatique du fichier brevets_6G.csv\",\n","                file_content,\n","                branch=BRANCH\n","            )\n","            print(\"‚úÖ Fichier cr√©√© avec succ√®s sur GitHub.\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå Erreur lors de l'upload sur GitHub: {e}\")\n","\n","# --- APPELER LA FONCTION D'UPLOAD ---\n","upload_file_to_github()\n","\n"],"metadata":{"id":"-9UPNMhPxU27","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746876190863,"user_tz":-120,"elapsed":152,"user":{"displayName":"Emmanuel Danton","userId":"16748182698026473705"}},"outputId":"565979ec-7f49-4f4f-cc11-f87c009339d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚ùå Erreur lors de l'upload sur GitHub: [Errno 2] No such file or directory: '/content/drive/MyDrive/acquisitionbrevet/Acquisition_Automatique_De_Donnees_Brevet.ipynb'\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   <h2>Lancement de l'application de visualisation\n","\n","\n"],"metadata":{"id":"Cm8qFpok19Cs"}},{"cell_type":"code","source":["!pip install streamlit pyngrok\n"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"T9Bd4RGn1yhh","executionInfo":{"status":"ok","timestamp":1741958907038,"user_tz":-60,"elapsed":3735,"user":{"displayName":"Emmanuel Danton","userId":"16748182698026473705"}},"outputId":"9f9e8861-c05d-486a-f69e-2c564c0a8b25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.43.2-py2.py3-none-any.whl.metadata (8.9 kB)\n","Collecting pyngrok\n","  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.30.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.43.2-py2.py3-none-any.whl (9.7 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n","Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n","Successfully installed pydeck-0.9.1 pyngrok-7.2.3 streamlit-1.43.2 watchdog-6.0.0\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","\n","st.title(\"üöÄ Mon Application Streamlit dans Google Colab\")\n","st.write(\"Ceci est une application ex√©cut√©e depuis un Notebook Colab !\")\n","\n","if st.button(\"Cliquez-moi !\"):\n","    st.success(\"Bravo ! Vous avez cliqu√© sur le bouton üéâ\")\n"],"metadata":{"id":"jJUaaU752QLp"},"execution_count":null,"outputs":[]}]}